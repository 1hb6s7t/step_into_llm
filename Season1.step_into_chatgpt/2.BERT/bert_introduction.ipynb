{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35bd8ac0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div align=center><img src=\"./assets/cover.png\" alt=\"bert-cover\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576ed71b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div align=center><img src=\"./assets/contents_1_2.png\" alt=\"table-of-contents\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f34239",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=center><img src=\"./assets/qr_code.jpeg\" alt=\"table-of-contents\" width=\"1300\"></div>\n",
    "\n",
    "https://github.com/mindspore-courses/step_into_chatgpt\n",
    "\n",
    "https://github.com/mindspore-lab/mindnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fabf36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3202年了，为什么还要学BERT\n",
    "\n",
    "- ### Decoder only模型当道： GPT3、Bloom、LLAMA、GLM\n",
    "\n",
    "    - #### Transformer Encoder结构在生成式任务上的缺陷\n",
    "\n",
    "    - #### BERT模型规模小\n",
    "\n",
    "    - #### Pretrain-Fintune范式的落寞\n",
    "\n",
    "- ### 2022年以前，学术界还是在倒腾BERT\n",
    "\n",
    "    - #### Finetune更容易针对单领域任务训练\n",
    "    \n",
    "    - #### BERT是首个大规模并行预训练的模型，也是当前的performance baseline\n",
    "    \n",
    "    - #### 由BERT入手学大模型训练、微调、Prompt最简单"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553a7118",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# NLP中的预训练模型\n",
    "\n",
    "语言模型的演变经历了以下几个阶段：\n",
    "\n",
    "<div align=center><img src=\"./assets/language_models.svg\" alt=\"language-models\" width=\"1000\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558644f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. `word2vec`/`Glove`将离散的文本数据转换为固定长度的**静态词向量**，后根据下游任务训练不同的**语言模型**；\n",
    "\n",
    "2. `ELMo`预训练模型将文本数据*结合上下文信息*，转换为**动态词向量**，后根据下游任务训练不同的**语言模型**；\n",
    "\n",
    "3. `BERT`同样将文本数据转换为**动态词向量**，能够更好地捕捉*句子级别的信息与语境信息*，后续只需finetune最后的**输出层**即可适配下游任务；\n",
    "\n",
    "4. `GPT`等预训练语言模型主要用于*文本生成类任务*，需要通过**prompt方法**来应用于下游任务，指导模型生成特定的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f242c5a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# BERT\n",
    "\n",
    "<div align=center><img src=\"./assets/bert-transfer-learning.png\"></div>\n",
    "\n",
    "BERT模型本质上是结合了`ELMo`模型与`GPT`模型的优势。\n",
    "\n",
    "- 相比于ELMo，BERT仅需改动最后的输出层，而非模型架构，便可以在下游任务中达到很好的效果；\n",
    "- 相比于GPT，BERT在处理词元表示时考虑到了双向上下文的信息；\n",
    "\n",
    "BERT通过两种无监督任务（Masked Language Modelling 和 Next Sentence Prediction）进行预训练，其次，在下游任务中对预训练Transformer编码器的所有参数进行微调，额外的输出层将从头开始训练。\n",
    "\n",
    "> Reference: [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](http://jalammar.github.io/illustrated-bert/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a5669",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# BERT 结构\n",
    "\n",
    "BERT（Bidirectional Encoder Representation from Transformers）是由Transformer的Encoder层堆叠而成，BERT的模型大小有如下两种：\n",
    "\n",
    "- BERT BASE：与Transformer参数量齐平，用于比较模型效果（110M parameters）\n",
    "- BERT LARGE：在BERT BASE基础上扩大参数量，达到了当时各任务最好的结果（340M parameters）\n",
    "\n",
    "| model | blocks | hidden size | attention heads |\n",
    "| :-----:| :----: | :----: | :----: |\n",
    "| Transformer | 6 | 512 | 8 |\n",
    "| BERT BASE | 12 | 768 | 12 |\n",
    "| BERT LARGE | 24 | 1024 | 16 |\n",
    "\n",
    "> Reference: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e625e",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"./assets/bert-base-bert-large-encoders.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42d1ce8",
   "metadata": {},
   "source": [
    "接受输入序列后，BERT会输出每个位置对应的向量（长度等于hidden size），在后续下游任务中，我们会选取与任务相关的位置的向量，输入到最终输出层中得到结果。\n",
    "\n",
    "如在诈骗邮件分类任务中，我们会将表示句子级别信息的`[CLS]` token所对应的vector，放入classfier中，得到对spam/not spam分类的预测。\n",
    "\n",
    "<div align=center><img src=\"./assets/bert-classifier.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27de31d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## BERT 输入\n",
    "\n",
    "- 针对句子对相关任务，将两个句子合并为一个句子对输入到Encoder中，`[CLS]` + 第一个句子 + `[SEP]` + 第二个句子 + `[SEP]`;\n",
    "- 针对单个文本相关任务，`[CLS]` + 句子 + \n",
    "`[SEP]`。\n",
    "\n",
    "在诈骗邮件分类中，输入为单个句子，在拆分为tokens后，在序列首尾分别添加`[CLS]`与`[SEP]`即可。\n",
    "\n",
    "<div align=center><img src=\"./assets/bert-input.png\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c39086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting git+https://openi.pcl.ac.cn/lvyufeng/mindnlp\n",
      "  Cloning https://openi.pcl.ac.cn/lvyufeng/mindnlp to /tmp/pip-req-build-hrpjpx1p\n",
      "  Running command git clone --filter=blob:none --quiet https://openi.pcl.ac.cn/lvyufeng/mindnlp /tmp/pip-req-build-hrpjpx1p\n",
      "  warning: filtering not recognized by server, ignoring\n",
      "  Resolved https://openi.pcl.ac.cn/lvyufeng/mindnlp to commit a90db347d4f868857ae82285a1144039b751a7a4\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting mindspore>=2.2.14 (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/69/3c/889efc96009a803702a8b81b111c72a78b2ea74f52efb0d22e27fa349d89/mindspore-2.3.0-cp39-none-any.whl (273.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.2/273.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/18/eb/fdb7eb9e48b7b02554e1664afd3bd3f117f6b6d6c5881438a0b055554f9b/tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/60/2d/963b266bb8f88492d5ab4232d74292af8beb5b6fdae97902df9e284d4c32/datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting evaluate (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/c2/d6/ff9baefc8fc679dcd9eb21b29da3ef10c81aa36be630a7ae78e4611588e1/evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers==0.19.1 (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/0f/cb/8fc733c8f251bac1e5c4ae52458c353b3faa98f41d734c226cad3783da03/tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/38/7f/3ba803bd6d726d65e480bee2aaeea79580d2e4836e4c6ebc27144c62ce51/safetensors-0.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/5f/01/c95e42eb86282b2c79305d3e0b0ca5a743f85a61262bb7130999c70b9374/sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/36/67/851cf82e2c47d46846cca15ba84f845e876257a54cb82f229d335cd5c67e/regex-2024.7.24-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.9/775.9 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting addict (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/6a/00/b08f23b7d7e1e14ce01419a467b583edbb93c6cdb8654e54a9cc579cd61f/addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting ml_dtypes (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/23/1c/06b52d3dcd75a81f6ca1e56514db6b21fe928f159cc5302428c1fed46562/ml_dtypes-0.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyctcdecode (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/a5/8a/93e2118411ae5e861d4f4ce65578c62e85d0f1d9cb389bd63bd57130604e/pyctcdecode-0.5.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting jieba (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytest==7.2.0 (from mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/67/68/a5eb36c3a8540594b6035e6cdae40c1ef1b6a2bfacbecc3d1a544583c078/pytest-7.2.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.8/316.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting attrs>=19.2.0 (from pytest==7.2.0->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/e0/44/827b2a91a5816512fcaf3cc4ebc465ccd5d598c45cefa6703fcf4a79018f/attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting iniconfig (from pytest==7.2.0->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ef/a6/62565a6e1cf69e10f5727360368e451d4b7f58beeac6173dc9db836a5b46/iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: packaging in /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.3.2) (24.1)\n",
      "Collecting pluggy<2.0,>=0.12 (from pytest==7.2.0->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/88/5f/e351af9a41f866ac3f1fac4ca0613908d9a41741cfcf2228f4ad853b697d/pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.3.2) (1.2.2)\n",
      "Collecting tomli>=1.0.0 (from pytest==7.2.0->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/97/75/10a9ebee3fd790d20926a90a2547f0bf78f371b2f13aa822c759680ca7b9/tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers==0.19.1->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/0f/36/83c0f0c7a5ec75738241c4c0c066097e4f74729716961db6a2905395015c/huggingface_hub-0.24.3-py3-none-any.whl (417 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.3/417.3 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy<2.0.0,>=1.20.0 (from mindspore>=2.2.14->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/54/30/c2a907b9443cf42b90c17ad10c1e8fa801975f01cb9764f3f8eb8aea638b/numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.13.0 (from mindspore>=2.2.14->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/27/e4/8dc4546be46873f8950cb44cdfe19b79d66d26e53c4ee5e3440406257fcd/protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.3/309.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: asttokens>=2.0.4 in /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.3.2) (2.4.1)\n",
      "Collecting pillow>=6.2.0 (from mindspore>=2.2.14->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/32/3f/c02268d0c6fb6b3958bdda673c17b315c821d97df29ae6969f20fb49388a/pillow-10.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.5.4 (from mindspore>=2.2.14->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/35/f5/d0ad1a96f80962ba65e2ce1de6a1e59edecd1f0a7b55990ed208848012e0/scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.3.2) (6.0.0)\n",
      "Collecting astunparse>=1.6.3 (from mindspore>=2.2.14->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting filelock (from datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ae/f0/48285f0262fe47103a4a45972ed2f9b93e4c80b8fd609fa98da78b2a5706/filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/af/61/bcd9b58e38ead6ad42b9ed00da33a3f862bc1d445e3d3164799c25550ac2/pyarrow-17.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow-hotfix (from datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/c9/7a/cef76fd8438a42f96db64ddaa85280485a9c395e7df3db8158cfec1eee34/dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas (from datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/bb/30/f6f1f1ac36250f50c421b1b6af08c35e5a8b5a84385ef928625336b93e6f/pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/63/93/812d78f70145c68c4e64533f4d625bea01236f27698febe15f0ceebc1566/xxhash-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.8/193.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess (from datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/da/d9/f7f9379981e39b8c2511c9e0326d212accacb82f12fbfdc1aa2ce2a7b2b6/multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ba/a3/16e9fe32187e9c8bc7f9b7bcd9728529faa725231a0c96f2f98714ff2fc5/fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp (from datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/4c/e6/061ab7e0084b7443f9bd7092853b5d0f97029157a58fcc8749cdad8aef0f/aiohttp-3.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.1 (from datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/7d/39/472f2554a0f1e825bd7c5afc11c817cd7a2f3657460f7159f691fbb37c51/PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.9/738.9 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2 (from requests->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/98/69/5d8751b4b670d623aa7a47bef061d69c279e9f922f6705147983aa76c3ce/charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.3/142.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5 (from requests->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/e5/3e/741d8c82801c347547f8a2a06aa57dbb1992be9e948df2ea0eda2c8b79e8/idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1 (from requests->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ca/1c/89ffc63a9605b583d5df2be791a27bc1a42b7c32bab68d3c8f2f73a98cd4/urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/1c/d5/c84e1a17bf61d4df64ca866a1c9a913874b4e9bdc131ec689a0ad013fb36/certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pygtrie<3.0,>=2.1 (from pyctcdecode->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ec/cd/bd196b2cf014afb1009de8b0f05ecd54011d881944e62763f3c1b1e8ef37/pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
      "Collecting hypothesis<7,>=6.14 (from pyctcdecode->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/dd/b6/619043aa33150cfbb2491f7d712a5a955cd3702056c6e436454477b5c18b/hypothesis-6.108.5-py3-none-any.whl (465 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.2/465.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages (from asttokens>=2.0.4->mindspore>=2.2.14->mindnlp==0.3.2) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages (from astunparse>=1.6.3->mindspore>=2.2.14->mindnlp==0.3.2) (0.43.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/07/b1/d9455cf313df7b2fe6c60a871eb96801b6e8fbdc7d736f6576492b4c97b3/aiohappyeyeballs-2.3.2-py3-none-any.whl (11 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/70/b0/6f1ebdabfb604e39a0f84428986b89ab55f246b64cddaa495f2c953e1f6b/frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp->datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/39/a9/1f8d42c8103bcb1da6bb719f1bc018594b5acc8eae56b3fec4720ebee225/multidict-6.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp->datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/69/ea/d7e961ea9b1b818a43b155ee512117be6ab9ab67c1e94967b2e64126e8e4/yarl-1.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.3/304.3 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp->datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1->mindnlp==0.3.2) (4.12.2)\n",
      "Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis<7,>=6.14->pyctcdecode->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages (from pandas->datasets->mindnlp==0.3.2) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7 (from pandas->datasets->mindnlp==0.3.2)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: mindnlp, jieba\n",
      "  Building wheel for mindnlp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mindnlp: filename=mindnlp-0.3.2-py3-none-any.whl size=7471871 sha256=328695be9d2ec5e1f94be4073a42c92fea364363ca0deb5f7d5ddaf86ee34d89\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mlk1qf2y/wheels/c2/ba/79/2d2ba93b28c3b18fea2459980f9ccf9a029367df342b66431b\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314459 sha256=a5c51b629e95397561c1c28ce242a982fba47b741ee3fc6c00d863a98080bb9f\n",
      "  Stored in directory: /home/ma-user/.cache/pip/wheels/2d/22/9e/9af7e8c2773513ac75905acfb75073922bcc1aa176f730a0c9\n",
      "Successfully built mindnlp jieba\n",
      "Installing collected packages: sortedcontainers, sentencepiece, pytz, pygtrie, jieba, addict, xxhash, urllib3, tzdata, tqdm, tomli, safetensors, regex, pyyaml, pyarrow-hotfix, protobuf, pluggy, pillow, numpy, multidict, iniconfig, idna, fsspec, frozenlist, filelock, dill, charset-normalizer, certifi, attrs, async-timeout, astunparse, aiohappyeyeballs, yarl, scipy, requests, pytest, pyarrow, pandas, multiprocess, ml_dtypes, hypothesis, aiosignal, pyctcdecode, mindspore, huggingface-hub, aiohttp, tokenizers, datasets, evaluate, mindnlp\n",
      "Successfully installed addict-2.4.0 aiohappyeyeballs-2.3.2 aiohttp-3.10.0 aiosignal-1.3.1 astunparse-1.6.3 async-timeout-4.0.3 attrs-23.2.0 certifi-2024.7.4 charset-normalizer-3.3.2 datasets-2.20.0 dill-0.3.8 evaluate-0.4.2 filelock-3.15.4 frozenlist-1.4.1 fsspec-2024.5.0 huggingface-hub-0.24.3 hypothesis-6.108.5 idna-3.7 iniconfig-2.0.0 jieba-0.42.1 mindnlp-0.3.2 mindspore-2.3.0 ml_dtypes-0.4.0 multidict-6.0.5 multiprocess-0.70.16 numpy-1.26.4 pandas-2.2.2 pillow-10.4.0 pluggy-1.5.0 protobuf-5.27.2 pyarrow-17.0.0 pyarrow-hotfix-0.6 pyctcdecode-0.5.0 pygtrie-2.5.0 pytest-7.2.0 pytz-2024.1 pyyaml-6.0.1 regex-2024.7.24 requests-2.32.3 safetensors-0.4.3 scipy-1.13.1 sentencepiece-0.2.0 sortedcontainers-2.4.0 tokenizers-0.19.1 tomli-2.0.1 tqdm-4.66.4 tzdata-2024.1 urllib3-2.2.2 xxhash-3.4.1 yarl-1.9.4\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting pytesseract\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/c5/54/ec007336f38d2d4ce61f3544af3e6855dacbf04a1ac8294f10cabe81146f/pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /home/ma-user/anaconda3/envs/python-3.9.0/lib/python3.9/site-packages (from pytesseract) (10.4.0)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.10\n"
     ]
    }
   ],
   "source": [
    "# install mindnlp\n",
    "!pip install git+https://openi.pcl.ac.cn/lvyufeng/mindnlp\n",
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad0c6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2393, 3159, 2089, 6968, 2080, 4651, 4121, 12839, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', 'help', 'prince', 'may', '##uk', '##o', 'transfer', 'huge', 'inheritance', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "sequence = 'help prince mayuko transfer huge inheritance'\n",
    "model_inputs = tokenizer(sequence)\n",
    "print(model_inputs)\n",
    "tokens = []\n",
    "for index in model_inputs['input_ids']:\n",
    "    tokens.append(tokenizer.convert_ids_to_tokens(index))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf4efc6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## BERT Embedding\n",
    "\n",
    "输入到BERT模型的信息由三部分内容组成：\n",
    "\n",
    "- 表示内容的token ids\n",
    "- 表示位置的position ids\n",
    "- 用于区分不同句子的token type ids\n",
    "\n",
    "三种信息分别进入Embedding层，得到token embeddings、position embeddings与segment embeddings；与Transformer不同，以上三种均为**可学习**的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1d92c5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align=center><img src=\"./assets/bert-embedding-modified.png\" alt=\"bert-embedding\" width=\"1000\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d04340e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mindspore\n",
    "from mindspore import nn\n",
    "import mindspore.common.dtype as mstype\n",
    "from mindspore.common.initializer import initializer, TruncatedNormal\n",
    "\n",
    "class BertEmbeddings(nn.Cell):\n",
    "    \"\"\"\n",
    "    Embeddings for BERT, include word, position and token_type\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, embedding_table=TruncatedNormal(config.initializer_range))\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size, embedding_table=TruncatedNormal(config.initializer_range))\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size, embedding_table=TruncatedNormal(config.initializer_range))\n",
    "        self.layer_norm = nn.LayerNorm((config.hidden_size,), epsilon=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(1 - config.hidden_dropout_prob)\n",
    "\n",
    "    def construct(self, input_ids, token_type_ids=None, position_ids=None):\n",
    "        seq_len = input_ids.shape[1]\n",
    "        if position_ids is None:\n",
    "            position_ids = mnp.arange(seq_len)\n",
    "            position_ids = position_ids.expand_dims(0).expand_as(input_ids)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = ops.zeros_like(input_ids)\n",
    "        \n",
    "        words_embeddings = self.word_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24afcb4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## BERT 模型构建\n",
    "\n",
    "BERT模型的构建与上一节课程的Transformer Encoder构建类似。\n",
    "\n",
    "分别构建multi-head attention层，feed-forward network，并在中间用add&norm连接，最后通过线性层与softmax层进行输出。\n",
    "\n",
    "<div align=center><img src=\"./assets/bert-model-architecture.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ad4de",
   "metadata": {},
   "source": [
    "### BERT self-attention 层\n",
    "\n",
    "<div align=center><img src=\"./assets/transformer_multi-headed_self-attention-recap.png\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5068b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSelfAttention(nn.Cell):\n",
    "    \"\"\"\n",
    "    Self attention layer for BERT.\n",
    "    \"\"\"\n",
    "    def __init__(self,  config):\n",
    "        super().__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"The hidden size {config.hidden_size} is not a multiple of the number of attention \"\n",
    "                f\"heads {config.num_attention_heads}\"\n",
    "            )\n",
    "        self.output_attentions = config.output_attentions\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = nn.Dense(config.hidden_size, self.all_head_size, \\\n",
    "            weight_init=TruncatedNormal(config.initializer_range))\n",
    "        self.key = nn.Dense(config.hidden_size, self.all_head_size, \\\n",
    "            weight_init=TruncatedNormal(config.initializer_range))\n",
    "        self.value = nn.Dense(config.hidden_size, self.all_head_size, \\\n",
    "            weight_init=TruncatedNormal(config.initializer_range))\n",
    "\n",
    "        self.dropout = Dropout(config.attention_probs_dropout_prob)\n",
    "        self.softmax = nn.Softmax(-1)\n",
    "        self.matmul = Matmul()\n",
    "\n",
    "    def transpose_for_scores(self, input_x):\n",
    "        \"\"\"\n",
    "        transpose for scores\n",
    "        [batch_size, seq_len, num_heads, head_size] to [batch_size, num_heads, seq_len, head_size]\n",
    "        \"\"\"\n",
    "        new_x_shape = input_x.shape[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        input_x = input_x.view(*new_x_shape)\n",
    "        return input_x.transpose(0, 2, 1, 3)\n",
    "\n",
    "    def construct(self, hidden_states, attention_mask=None, head_mask=None):\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "        attention_scores = self.matmul(query_layer, key_layer.swapaxes(-1, -2))\n",
    "        attention_scores = attention_scores / ops.sqrt(Tensor(self.attention_head_size, mstype.float32))\n",
    "        if attention_mask is not None:\n",
    "            attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        attention_probs = self.softmax(attention_scores)\n",
    "\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        if head_mask is not None:\n",
    "            attention_probs = attention_probs * head_mask\n",
    "\n",
    "        context_layer = self.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.transpose(0, 2, 1, 3)\n",
    "        new_context_layer_shape = context_layer.shape[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "        outputs = (context_layer, attention_probs) if self.output_attentions else (context_layer,)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9983cb64",
   "metadata": {},
   "source": [
    "### BERT self-attention 输出层 \n",
    "\n",
    "- BERTSelfOutput：residual connection + layer normalization\n",
    "- BERTAttention: self-attention + add&norm\n",
    "\n",
    "<div align=center><img src=\"./assets/bert-attention-code.png\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7ec92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSelfOutput(nn.Cell):\n",
    "    r\"\"\"\n",
    "    Bert Self Output\n",
    "    self-attention output + residual connection + layer norm\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Dense(config.hidden_size, config.hidden_size, \\\n",
    "            weight_init=TruncatedNormal(config.initializer_range))\n",
    "        self.layer_norm = nn.LayerNorm((config.hidden_size,), epsilon=1e-12)\n",
    "        self.dropout = Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def construct(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.layer_norm(hidden_states + input_tensor)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef35f5",
   "metadata": {},
   "source": [
    "### BERT feed-forward 层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "073f2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertIntermediate(nn.Cell):\n",
    "    r\"\"\"\n",
    "    Bert Intermediate\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Dense(config.hidden_size, config.intermediate_size, \\\n",
    "            weight_init=TruncatedNormal(config.initializer_range))\n",
    "        self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "\n",
    "    def construct(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd863caa",
   "metadata": {},
   "source": [
    "### BERT 最后的Add&Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0732f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertOutput(nn.Cell):\n",
    "    r\"\"\"\n",
    "    Bert Output\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Dense(config.intermediate_size, config.hidden_size, \\\n",
    "            weight_init=TruncatedNormal(config.initializer_range))\n",
    "        self.layer_norm = nn.LayerNorm((config.hidden_size,), epsilon=1e-12)\n",
    "        self.dropout = Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def construct(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self. layer_norm(hidden_states + input_tensor)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66995cbe",
   "metadata": {},
   "source": [
    "### BERT Encoder\n",
    "\n",
    "- BertLayer：Encoder Layer，集合了self-attention, feed-forward并通过add&norm连接\n",
    "- BertEnocoder：通过Encoder Layer堆叠起来的Encoder结构\n",
    "\n",
    "<div align=center><img src=\"./assets/bert-model-code.png\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7752a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(nn.Cell):\n",
    "    r\"\"\"\n",
    "    Bert Layer\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention = BertAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def construct(self, hidden_states, attention_mask=None, head_mask=None):\n",
    "        attention_outputs = self.attention(hidden_states, attention_mask, head_mask)\n",
    "        attention_output = attention_outputs[0]\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        outputs = (layer_output,) + attention_outputs[1:]\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class BertEncoder(nn.Cell):\n",
    "    r\"\"\"\n",
    "    Bert Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.output_attentions = config.output_attentions\n",
    "        self.output_hidden_states = config.output_hidden_states\n",
    "        self.layer = nn.CellList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def construct(self, hidden_states, attention_mask=None, head_mask=None):\n",
    "        all_hidden_states = ()\n",
    "        all_attentions = ()\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if self.output_hidden_states:\n",
    "                all_hidden_states += (hidden_states,)\n",
    "\n",
    "            layer_outputs = layer_module(hidden_states, attention_mask, head_mask[i])\n",
    "            hidden_states = layer_outputs[0]\n",
    "\n",
    "            if self.output_attentions:\n",
    "                all_attentions += (layer_outputs[1],)\n",
    "\n",
    "        if self.output_hidden_states:\n",
    "            all_hidden_states += (hidden_states,)\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "        if self.output_hidden_states:\n",
    "            outputs += (all_hidden_states,)\n",
    "        if self.output_attentions:\n",
    "            outputs += (all_attentions,)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546a1b39",
   "metadata": {},
   "source": [
    "## BERT 输出\n",
    "\n",
    "BERT会针对每一个位置输出大小为hidden size的向量，在下游任务中，会根据任务内容的不同，选取不同的向量放入输出层。\n",
    "- 我们一般称`[CLS]`经过线性层+激活函数tanh的输出为**pooler output**，用于句子级别的分类/回归任务;\n",
    "- 我们一般称BERT输出的每个位置对应的vector为**sequence output**,用于词语级别的分类任务；\n",
    "\n",
    "<div align=center><img src=\"./assets/bert-output.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3466d706",
   "metadata": {},
   "source": [
    "### BERT Pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50b79508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertPooler(nn.Cell):\n",
    "    r\"\"\"\n",
    "    Bert Pooler\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Dense(config.hidden_size, config.hidden_size, \\\n",
    "            activation='tanh', weight_init=TruncatedNormal(config.initializer_range))\n",
    "\n",
    "    def construct(self, hidden_states):\n",
    "\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0df426",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## BERT 预训练\n",
    "\n",
    "BERT通过Masked LM（masked language model）与NSP（next sentence prediction）获取词语和句子级别的特征。\n",
    "\n",
    "<div align=center><img src=\"./assets/bert_pretrain_finetune.jpg\" alt=\"bert-pretrain\" width=\"1000\"></div>\n",
    "\n",
    "> <font size=2>图片来源：Devlin, J.; Chang, M. W.; Lee, K.; Toutanova, K. BERT: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef77d903",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Masked Language Model (Masked LM)\n",
    "\n",
    "BERT模型通过Masked LM捕捉**词语层面**的信息。\n",
    "\n",
    "我们随机将每个句子中15%的词语进行遮盖，替换成掩码\\<mask\\>。在训练过程中，模型会对句子进行“完形填空”，预测这些被遮盖的词语是什么，通过减小被mask词语的损失值来对模型进行优化。\n",
    "\n",
    "<div align=center><img src=\"./assets/masked_lm.png\" alt=\"masked-lm\" width=\"1000\"></div>\n",
    "\n",
    "> <font size=2>图片来源: [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa96afc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "由于\\<mask\\>仅在预训练中出现，为了让预训练和微调中的数据处理尽可能接近，我们在随机mask的时候进行如下操作：\n",
    "- 80%的概率替换为\\<mask\\>\n",
    "- 10%的概率替换为文本中的随机词\n",
    "- 10%的概率不进行替换，保持原有的词元\n",
    "\n",
    "<div align=center><img src=\"./assets/masked_lm_2.png\" alt=\"masked-lm-2\" width=\"1000\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4469a1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "我们通过`BERTPredictionHeadTranform`实现单层感知机，对被遮盖的词元进行预测。在前向网络中，我们需要输入BERT模型的编码结果`hidden_states`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53d4e932",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "activation_map = {\n",
    "    'relu': nn.ReLU(),\n",
    "    'gelu': nn.GELU(False),\n",
    "    'gelu_approximate': nn.GELU(),\n",
    "    'swish':nn.SiLU()\n",
    "}\n",
    "\n",
    "class BertPredictionHeadTransform(nn.Cell):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Dense(config.hidden_size, config.hidden_size, weight_init=TruncatedNormal(config.initializer_range))\n",
    "        self.transform_act_fn = activation_map.get(config.hidden_act, nn.GELU(False))\n",
    "        self.layer_norm = nn.LayerNorm((config.hidden_size,), epsilon=config.layer_norm_eps)\n",
    "    \n",
    "    def construct(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.transform_act_fn(hidden_states)\n",
    "        hidden_states = self.layer_norm(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c825d61f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "根据被遮盖的词元位置`masked_lm_positions`，获得这些词元的预测输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de0cc3f8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import mindspore.ops as ops\n",
    "import mindspore.numpy as mnp\n",
    "from mindspore import Parameter, Tensor\n",
    "\n",
    "class BertLMPredictionHead(nn.Cell):\n",
    "    def __init__(self, config):\n",
    "        super(BertLMPredictionHead, self).__init__()\n",
    "        self.transform = BertPredictionHeadTransform(config)\n",
    "\n",
    "        self.decoder = nn.Dense(config.hidden_size, config.vocab_size, has_bias=False, weight_init=TruncatedNormal(config.initializer_range))\n",
    "\n",
    "        self.bias = Parameter(initializer('zeros', config.vocab_size), 'bias')\n",
    "\n",
    "    def construct(self, hidden_states, masked_lm_positions):\n",
    "\n",
    "        batch_size, seq_len, hidden_size = hidden_states.shape\n",
    "        if masked_lm_positions is not None:\n",
    "            flat_offsets = mnp.arange(batch_size) * seq_len\n",
    "            flat_position = (masked_lm_positions + flat_offsets.reshape(-1, 1)).reshape(-1)\n",
    "            flat_sequence_tensor = hidden_states.reshape(-1, hidden_size)\n",
    "            hidden_states = ops.gather(flat_sequence_tensor, flat_position, 0)\n",
    "        hidden_states = self.transform(hidden_states)\n",
    "        hidden_states = self.decoder(hidden_states) + self.bias\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c0e09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Next Sentence Prediction (NSP)\n",
    "\n",
    "BERT通过NSP捕捉**句子级别**的信息，使其可以理解句子与句子之间的联系，从而能够应用于问答或者推理任务。\n",
    "\n",
    "NSP本质上是一个**二分类任务**，通过输入一个句子对，判断两句话是否为连续句子。输入的两个句子A和B中，B有50%的概率是A的下一句。\n",
    "\n",
    "<div align=center><img src=\"./assets/nsp.png\" alt=\"nsp\" width=\"500\"></div>\n",
    "\n",
    "> <font size=2>图片来源: [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert)</font>\n",
    "\n",
    "另外，输入的内容最好是document-level的语料，而非sentence-level的语料，这样训练出的模型可以具备抓取长序列特征的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209b829",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "在这里，我们使用一个单隐藏层的多层感知机`BERTPooler`进行二分类预测。因为特殊占位符\\<cls\\>在预训练中对应了句子级别的特征信息，所以多层感知机分类器只需要输出\\<cls\\>对应的隐藏层输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1784651",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class BertPooler(nn.Cell):\n",
    "    def __init__(self, config):\n",
    "        super(BertPooler, self).__init__()\n",
    "        self.dense = nn.Dense(config.hidden_size, config.hidden_size, activation='tanh', weight_init=TruncatedNormal(config.initializer_range))\n",
    "    \n",
    "    def construct(self, hidden_states):\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75af11",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "最后，多层感知机分类器的输出通过一个线性层`self.seq_relationship`，输出对nsp的预测。\n",
    "\n",
    "在`BERTPreTrainingHeads`中，我们对以上提到的两种方式进行整合。最终输出Maked LM（`prediction scores`）和NSP（`seq_realtionship_score`）的预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edc1f2a8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class BertPreTrainingHeads(nn.Cell):\n",
    "    def __init__(self, config):\n",
    "        super(BertPreTrainingHeads, self).__init__()\n",
    "        self.predictions = BertLMPredictionHead(config)\n",
    "        self.seq_relationship = nn.Dense(config.hidden_size, 2, weight_init=TruncatedNormal(config.initializer_range))\n",
    "    \n",
    "    def construct(self, sequence_output, pooled_output, masked_lm_positions):\n",
    "        prediction_scores = self.predictions(sequence_output, masked_lm_positions)\n",
    "        seq_relationship_score = self.seq_relationship(pooled_output)\n",
    "        return prediction_scores, seq_relationship_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd5d8b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### BERT预训练代码整合\n",
    "\n",
    "我们将上述的类进行实例化，并借此回顾一下BERT预训练的整体流程。\n",
    "\n",
    "1. `BertModel`构建BERT模型；\n",
    "2. `BertPretrainingHeads`整合了Masked LM与NSP两个训练任务， 输出预测结果；\n",
    "    - `BertLMPredictionHead`：输入BERT编码与\\<mask\\>的位置，输出对应位置词元的预测；\n",
    "    - `BERTPooler`：输入BERT编码，输出对\\<cls\\>的隐藏状态，并在`BertPretrainingHeads`中通过线性层输出预测结果；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dc5a310",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class BertForPretraining(nn.Cell):\n",
    "    def __init__(self, config, *args, **kwargs):\n",
    "        super().__init__(config, *args, **kwargs)\n",
    "        self.bert = BertModel(config)\n",
    "        self.cls = BertPreTrainingHeads(config)\n",
    "        self.vocab_size = config.vocab_size\n",
    "\n",
    "        self.cls.predictions.decoder.weight = self.bert.embeddings.word_embeddings.embedding_table\n",
    "\n",
    "    def construct(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, masked_lm_positions=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask\n",
    "        )\n",
    "\n",
    "        sequence_output, pooled_output = outputs[:2]\n",
    "        prediction_scores, seq_relationship_score = self.cls(sequence_output, pooled_output, masked_lm_positions)\n",
    "\n",
    "        outputs = (prediction_scores, seq_relationship_score,) + outputs[2:]\n",
    "\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "幻灯片",
  "kernelspec": {
   "display_name": "python-3.9.0",
   "language": "python",
   "name": "python-3.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
